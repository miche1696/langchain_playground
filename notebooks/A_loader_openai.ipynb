{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757f0f5a",
   "metadata": {},
   "source": [
    "# Processing: Load, Chunk, and Prepare for Vector DB\n",
    "\n",
    "This notebook demonstrates a step-by-step approach to loading, enriching,\n",
    "chunking, and storing documents into a vector database.\n",
    "It compares different outputs at each stage interactively with helpful visualizations.\n",
    "\n",
    "Create from scratch a chain that: \n",
    "- takes an input document. (In this case many Arxiv pdf documents.)\n",
    "- Chunks the document, keeping the metadata.\n",
    "- Embed the document chunks.\n",
    "- Saves the embeddings into a vector DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f71e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c404115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Supports all arguments of `ArxivAPIWrapper`\n",
    "loader = ArxivLoader(\n",
    "    query=\"LLM\",\n",
    "    load_max_docs=50,\n",
    "    top_k_results=20\n",
    "    # doc_content_chars_max=1000,\n",
    "    # load_all_available_meta=False,\n",
    "    # ...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df738bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cca765",
   "metadata": {},
   "source": [
    "# Splitter - (There are the variables that change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860cd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be2a4bd",
   "metadata": {},
   "source": [
    "# Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b22f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chunks = []\n",
    "chunk_by_doc = {}\n",
    "for doc in docs:\n",
    "    doc_chunks = []\n",
    "    for i, chunk in enumerate(text_splitter.split_text(doc.page_content)):\n",
    "        metadata = doc.metadata.copy()\n",
    "        metadata[\"chunk_index\"] = i\n",
    "        doc_chunks.append(Document(page_content=chunk, metadata=metadata))\n",
    "    chunk_by_doc[doc.metadata.get(\"Title\", \"Document\")] = (\n",
    "        doc_chunks\n",
    "    )\n",
    "    final_chunks.extend(doc_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957e760",
   "metadata": {},
   "source": [
    "# Storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "728fc94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Stored in Qdrant Vector DB ---\n",
      "Collection: LLM-papers openai\n"
     ]
    }
   ],
   "source": [
    "# ## Step 3: Store in Qdrant Vector DB\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "db = Qdrant.from_documents(\n",
    "    documents=final_chunks,\n",
    "    embedding=embedding,\n",
    "    location=\"localhost:6333\",\n",
    "    collection_name=\"LLM-papers openai\",\n",
    "    prefer_grpc=False,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Stored in Qdrant Vector DB ---\")\n",
    "print(f\"Collection: {db.collection_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-playground-ABXqpzBr-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
